colData = samples,
design = ~ condition)
dds
names(assays(dds)) # list the stored assays
assays(dds)[["avgTxLength"]] %>% head() # uses assays() function with typical indexing operators.
counts(dds) %>% head() # uses counts() function to specifically extract the counts
names(assays(dds)) # list the stored assays
assays(dds)[["counts"]] %>% head() # uses assays() function with typical indexing operators.
counts(dds) %>% head() # uses counts() function to specifically extract the counts
colData(dds)
rowData(dds)
head(counts(dds))
head(txi$counts)
# keep only rows with with counts summing up to 10 or more
dds <- dds[rowSums(counts(dds)) >= 10,]
vst_counts <- vst(dds, blind=F)
plotPCA(vst_counts,
intgroup=c("side", "treatment"), # indicate how to label the points
returnData=F, # plot only
ntop=500) # use only 500 most variable genes.
resultsNames(dds)
dds <- DESeq(dds)
dds
resultsNames(dds)
res<-results(dds)
res
counts(dds)[rownames(res)[is.na(res$padj)],] %>% head(15)
# 1. using the result names:
results(dds, name="condition_white_dorsal_vs_black_dorsal")
# 2. using contrasts:
results(dds, contrast=c("condition","white_dorsal","black_dorsal"))
# white dorsal vs white ventral
res_wD_wV<-results(dds, contrast=c("condition","white_dorsal","white_ventral"))
# black dorsal vs black ventral
res_bD_bV<-results(dds, contrast=c("condition","black_dorsal","black_ventral"))
# black dorsal vs white dorsal
res_bD_wD<-results(dds, contrast=c("condition","black_dorsal","white_dorsal"))
# black ventral vs white ventral
res_bV_wV<-results(dds, contrast=c("condition","black_ventral","white_ventral"))
res<-list(bD_bV = res_bD_bV,
wD_wV = res_wD_wV,
bV_wV = res_bV_wV,
bD_wD = res_bD_wD)
# single comparison, here using a padj cutoff of 0.05
summary(res_bD_bV, alpha=0.05)
# for all comparisons:
lapply(res, summary, alpha=0.05)
# for all comparisons:
sapply(res, summary, alpha=0.05)
# for all comparisons:
sapply(res, summary, alpha=0.05) -> test
View(test)
# for all comparisons:
sapply(res, FUN=summary, alpha=0.05)
# single comparison, here using a padj cutoff of 0.05
summary(res_bD_bV, alpha=0.05)
summary
# for all comparisons:
sapply(res, DESeq2::summary, alpha=0.05)
# for all comparisons:
sapply(res, summary, alpha=0.05)
# for all comparisons:
for(i in 1:length(res)){
summary(res, alpha=0.5)
}
summary(res[[i]], alpha=0.5)
# for all comparisons:
for(i in 1:length(res)){
summary(res[[i]], alpha=0.5)
}
# for all comparisons:
for(i in 1:length(res)){
print(names(res)[i])
summary(res[[i]], alpha=0.5)
}
# for all comparisons:
for(i in 1:length(res)){
print(names(res)[i])
summary(res[[i]], alpha=0.5)
}
# for all comparisons:
for(i in 1:length(res)){
print(names(res)[i])
summary(res[[i]], alpha=0.5)
}
summary(res_bD_bV, alpha=0.05)
summary(res_wD_wV, alpha=0.05)
summary(res_bD_bV, alpha=0.05)
summary(res_bD_wD, alpha=0.05)
summary(res_bD_wD, alpha=0.05)
# single plot
DESeq2::plotMA(res_bD_bV)
# all comparisons (with lapply)
par(mfrow=c(2,2)) # divide plot area in 4
lapply(names(res),function(i) DESeq2::plotMA(res[[i]], main=i, alpha=0.05))
par(mfrow=c(1,1))
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
scale_y_continuous(limits=c(-3, 3), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
par(mfrow=c(2,2))
# single plot
DESeq2::plotMA(res_wD_wV)
DESeq2::plotMA(res_bD_bV)
DESeq2::plotMA(res_bD_wD)
DESeq2::plotMA(res_bD_wD)
par(mfrow=c(1,1))
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
scale_y_continuous(limits=c(-3, 3), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
#scale_y_continuous(limits=c(-3, 3), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
scale_y_continuous(limits=c(-5, 5), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
# export individual results table
write.csv(as.data.frame(res_wD_wV), "./results/deseq2_res_wD_wV.csv")
write.csv(as.data.frame(res_bD_bV), "./results/deseq2_res_bD_bV.csv")
write.csv(as.data.frame(res_bD_wD), "./results/deseq2_res_bD_wD.csv")
write.csv(as.data.frame(res_bD_wD), "./results/deseq2_res_bD_wD.csv")
DESeq2::plotMA(res_bV_wV)
# for all comparisons:
par(mfrow=c(2,2))
par(mar=c(4,4,1,1))
hist(res_wD_wV$pvalue, breaks=50, col="grey", main="")
hist(res_bD_bV$pvalue, breaks=50, col="grey", main="")
hist(res_bD_wD$pvalue, breaks=50, col="grey", main="")
hist(res_bV_wV$pvalue, breaks=50, col="grey", main="")
par(mfrow=c(1,1))
plotDispEsts(dds)
# set working directory
#setwd("~/Documents/git_projects/PoE23/")
setwd("~/Documents/teaching/principals_of_evolution23/PoE23_rnaseq/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,DESeq2, ageglm,ggVennDiagram, UpSetR,plotly,ggrepel)
BiocManager::install("apeglm")
# DEG object
dds<-readRDS("./results/deseq2_dds.rds")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,
eval = FALSE,
message=FALSE,
error=FALSE)
knitr::opts_knit$set(root.dir = '../')
library(webexercises)
# Chunk 2
# set working directory
#setwd("~/Documents/git_projects/PoE23/")
setwd("~/Documents/teaching/principals_of_evolution23/PoE23_rnaseq/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse, DESeq2,viridis,scales)
# Chunk 3
txi<-readRDS("./data/salmon_gene_counts.rds")
samples<-read_csv("./data/design_matrix.csv")
# Chunk 4
samples <- samples %>%
filter(tissue=="skin") %>%
mutate(condition=as.factor(paste(treatment, side, sep="_")))
## filter txi matrices
txi$abundance<-txi$abundance[,samples$sample_id]
txi$counts<-txi$counts[,samples$sample_id]
txi$length<-txi$length[,samples$sample_id]
# Chunk 5
dds <- DESeqDataSetFromTximport(txi,
colData = samples,
design = ~ condition)
# Chunk 6
dds
# Chunk 7
names(assays(dds)) # list the stored assays
assays(dds)[["counts"]] %>% head() # uses assays() function with typical indexing operators to get e.g. the counts
counts(dds) %>% head() # uses counts() function to specifically extract the counts
# Chunk 8
colData(dds)
# Chunk 9
rowData(dds)
# Chunk 10
head(counts(dds))
head(txi$counts)
# Chunk 11
# keep only rows with with counts summing up to 10 or more
dds <- dds[rowSums(counts(dds)) >= 10,]
# Chunk 12
dds <- DESeq(dds)
dds
# Chunk 13
resultsNames(dds)
# Chunk 14
res<-results(dds)
res
# Chunk 15
counts(dds)[rownames(res)[is.na(res$padj)],] %>% head(15)
# Chunk 16
# 1. using the result names:
results(dds, name="condition_white_dorsal_vs_black_dorsal")
# 2. using contrasts:
results(dds, contrast=c("condition","white_dorsal","black_dorsal"))
# Chunk 17
# white dorsal vs white ventral
res_wD_wV<-results(dds, contrast=c("condition","white_dorsal","white_ventral"))
# black dorsal vs black ventral
res_bD_bV<-results(dds, contrast=c("condition","black_dorsal","black_ventral"))
# black dorsal vs white dorsal
res_bD_wD<-results(dds, contrast=c("condition","black_dorsal","white_dorsal"))
# black ventral vs white ventral
res_bV_wV<-results(dds, contrast=c("condition","black_ventral","white_ventral"))
# Chunk 18
summary(res_wD_wV, alpha=0.05)
summary(res_bD_bV, alpha=0.05)
summary(res_bD_wD, alpha=0.05)
summary(res_bV_wV, alpha=0.05)
# Chunk 19
par(mfrow=c(2,2))
# single plot
DESeq2::plotMA(res_wD_wV)
DESeq2::plotMA(res_bD_bV)
DESeq2::plotMA(res_bD_wD)
DESeq2::plotMA(res_bV_wV)
par(mfrow=c(1,1))
# Chunk 20
res_bD_bV %>%
as.data.frame() %>%
ggplot(aes(baseMean, log2FoldChange, colour=padj)) +
geom_point(size=1) +
scale_y_continuous(limits=c(-5, 5), oob=squish) + # oob from the scales package is needed to "squish" points falling outside the axis limits
scale_x_log10() +
geom_hline(yintercept = 0, colour="red", size=1, linetype="longdash") +
labs(x="mean of normalized counts", y="log fold change") +
scale_colour_viridis(direction=-1, trans='sqrt') +
geom_density_2d(colour="blue", size=0.5) +
theme_bw()
# Chunk 21
# make a results folder if it does not yet exist
dir.create("results", showWarnings = FALSE)
# export individual results tables like so:
write.csv(as.data.frame(res_wD_wV), "./results/deseq2_res_wD_wV.csv")
# but for convenience, we can export them all as a list object and save it as an .rds file
saveRDS(list(bD_bV = res_bD_bV,
wD_wV = res_wD_wV,
bV_wV = res_bV_wV,
bD_wD = res_bD_wD),
"./results/deseq2_results.rds")
# export the DESeq2 object as an .rds files
saveRDS(dds, "./results/deseq2_dds.rds")
# set working directory
#setwd("~/Documents/git_projects/PoE23/")
setwd("~/Documents/teaching/principals_of_evolution23/PoE23_rnaseq/")
# DEG object
dds<-readRDS("./results/deseq2_dds.rds")
# the list of DEG results
res<-readRDS("./results/deseq2_results.rds")
# Load BLAST results
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
head(xtrop, 20)
xtrop<-read_csv("data/PCU23_annotations_xtr105_genes.csv")
head(xtrop, 20)
summary(res$bD_bV, alpha=0.05)
# For a single comparison
res$bD_bV %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
# turn it into a function so we can apply it to a list!
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
#  extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
# comparing just the dorsal vs. ventral
ggVennDiagram(sig_deg[c("bD_bV","wD_wV")],
label_alpha = 0) +
scale_fill_gradient(low="blue",high = "gold")
ggVennDiagram(sig_deg,
label_alpha = 0) +
scale_fill_gradient(low="blue",high = "gold")
upset(fromList(sig_deg),
number.angles = 0, point.size = 3, line.size = 1,
sets.x.label = "Number of DEGs",
set_size.show	= TRUE,
set_size.scale_max = max(sapply(sig_deg, length))+50, # needed only to expand the axis a bit
text.scale = c(1.2, 1.2, 1.2, 1.2, 1.5, 1.5),
order.by=c("degree","freq"))
# apeglm shrinkage can only be done on already calculated coefficients:
resultsNames(dds)
bD_bV_res <- results(dds,
contrast= c("condition","white_ventral", "black_dorsal"))
bD_bV_res
# with shrinkage
bD_bV_shr<-lfcShrink(dds,
coef="condition_white_ventral_vs_black_dorsal",
type="apeglm")
bD_bV_shr
par(mfrow=c(1,2))
par(mar=c(4,4,4,1))
DESeq2::plotMA(bD_bV_res, main="MLE")
DESeq2::plotMA(bD_bV_shr, main="MAP")
par(mfrow=c(1,2))
par(mar=c(4,4,1,1))
# p values
plot(bD_bV_res$padj~bD_bV_shr$padj,
xlab="adjusted p-value (shrunk)",
ylab="adjusted p-value (MLE)")
# fold changes
plot(bD_bV_res$log2FoldChange~bD_bV_shr$log2FoldChange,
xlab="Fold Change (shrunk)",
ylab="Fold Change (MLE)")
par(mfrow=c(1,1))
res$bD_bV %>%
as_tibble(rownames = "gene_id") %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj))) +
geom_point(alpha=0.75, shape=16)
gg_res <- res %>%
lapply(as_tibble,rownames = "gene_id") %>%
bind_rows(.id="comparison") %>%
drop_na(padj) %>% # drop all genes with NAs
filter(padj<0.5) %>% # reduce the number of points that need to be plotted
mutate(sig= padj<0.05 & abs(log2FoldChange)>=2) %>% # make a variable to indicate if a gene is significant based on a specific thresholds
left_join(xtrop, by=c("gene_id")) %>% # add annotations
ggplot(aes(x=log2FoldChange, y=-log10(padj), color=sig,
text=paste0("</br>Pcu23 gene: ", gene_id,
"</br>Pcu23 peptide: ", pep_description,
"</br>X.tr peptide: ", xtr_pep_name_x
)
)) +
geom_point(alpha=0.75, shape=16) +
facet_wrap(~comparison, ncol = 2, scales = "free") +
xlim(-15,15) +
theme_minimal() +
theme(legend.position = "none")
gg_res
gg_res
# we can now turn this into an interactive plot:
ggplotly(gg_res, tooltip="text")
res$bD_wD %>%
as_tibble(rownames = "gene_id") %>%
drop_na(padj) %>% # drop all genes with NAs
#filter(padj<0.99) %>% # reduce the number of points that need to be plotted
mutate(sig= padj<0.05 & abs(log2FoldChange)>=2) %>% # make a variable to indicate if a gene is significant based on a specific thresholds
left_join(xtrop, by=c("gene_id")) %>% # add annotations
filter(padj<0.5) %>%
ggplot(aes(x=log2FoldChange, y=-log10(padj), color=sig)) +
geom_point(alpha=0.75, shape=16) +
geom_text_repel(data=. %>% filter(sig),
aes(label=xtr_pep_name_x),
max.overlaps = 50,
size=2) +
xlim(-10,10) +
ggtitle("DEGs in Black Dorsal Skin in Comparison to White Dorsal Skin") +
theme_bw() +
theme(legend.position = "none")
# the list of DEG results from the previous exercises
res<-readRDS("./results/deseq2_results.rds")
# the annotations
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
# make a function that extracts matching X. tropicalis IDs
extract_xtr<-function(x) {
return(
xtrop %>%
filter(gene_id %in% x) %>%
pull(xtr_pep_id_x) %>%
unique()
)
}
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
str(xtr_deg)
sapply(sig_deg, length)
sapply(xtr_deg, length)
xtr_bg<-extract_xtr(rownames(res$bD_bV))
str(xtr_bg)
# set base url:
set_base_url("http://biit.cs.ut.ee/gprofiler")
# run the analysis
res_ora<-gost(multi_query = FALSE, # returns separate results tables for multiquery
custom_bg = xtr_bg, # our background
query=xtr_deg, # our list of gene sets
organism="xtropicalis", # the organism our annotations belong to
exclude_iea = FALSE, # include GO terms that were electronically assigned
correction_method = "gSCS", # the recommended multiple testing correction.
sources=c("GO:BP","GO:CC","GO:MF", "KEGG","REAC"), # the functional sets we are interested in
evcodes=FALSE, ## evcodes TRUE needed for downstream analysis like enrichment maps in Cytoscape, but this takes longer.
significant= FALSE) # return all terms, not just the significant ones
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,
eval = FALSE,
message=FALSE,
error=FALSE)
knitr::opts_knit$set(root.dir = '../')
library("webexercises")
# Chunk 2
# set working directory
#setwd("~/Documents/git_projects/PoE23/")
setwd("~/Documents/teaching/principals_of_evolution23/PoE23_rnaseq/")
# install pacman if not already installed
if (!require("pacman")) install.packages("pacman")
# use pacman to load libraries
pacman::p_load(tidyverse,gprofiler2)
# Chunk 3
# the list of DEG results from the previous exercises
res<-readRDS("./results/deseq2_results.rds")
# the annotations
xtrop<-read_csv("./data/PCU23_annotations_xtr105.csv")
# Chunk 4
extract_degs<-function(x) {
return(
x %>%
as_tibble(rownames = "gene") %>%
filter(padj<0.05) %>%
pull(gene)
)
}
# now extract all
sig_deg<-lapply(res, FUN=extract_degs)
str(sig_deg)
# Chunk 5
# make a function that extracts matching X. tropicalis IDs
extract_xtr<-function(x) {
return(
xtrop %>%
filter(gene_id %in% x) %>%
pull(xtr_pep_id_x) %>%
unique()
)
}
# apply function to list of Pelobates IDs
xtr_deg<-lapply(sig_deg, FUN=extract_xtr)
str(xtr_deg)
# Chunk 6
sapply(sig_deg, length)
sapply(xtr_deg, length)
# Chunk 7
xtr_bg<-extract_xtr(rownames(res$bD_bV))
str(xtr_bg)
# set base url:
set_base_url("https://biit.cs.ut.ee/gprofiler_archive3/e105_eg52_p16/gost")
# run the analysis
res_ora<-gost(multi_query = FALSE, # returns separate results tables for multiquery
custom_bg = xtr_bg, # our background
query=xtr_deg, # our list of gene sets
organism="xtropicalis", # the organism our annotations belong to
exclude_iea = FALSE, # include GO terms that were electronically assigned
correction_method = "gSCS", # the recommended multiple testing correction.
sources=c("GO:BP","GO:CC","GO:MF", "KEGG","REAC"), # the functional sets we are interested in
evcodes=FALSE, ## evcodes TRUE needed for downstream analysis like enrichment maps in Cytoscape, but this takes longer.
significant= FALSE) # return all terms, not just the significant ones
# set base url:
set_base_url("https://biit.cs.ut.ee/gprofiler_archive3/e105_eg52_p16/gost")
# run the analysis
res_ora<-gost(multi_query = FALSE, # returns separate results tables for multiquery
custom_bg = xtr_bg, # our background
query=xtr_deg, # our list of gene sets
organism="xtropicalis", # the organism our annotations belong to
exclude_iea = FALSE, # include GO terms that were electronically assigned
correction_method = "gSCS", # the recommended multiple testing correction.
sources=c("GO:BP","GO:CC","GO:MF", "KEGG","REAC"), # the functional sets we are interested in
evcodes=FALSE, ## evcodes TRUE needed for downstream analysis like enrichment maps in Cytoscape, but this takes longer.
significant= FALSE) # return all terms, not just the significant ones
# the results are stored as a "results" dataframe
head(res_ora$result)
